---
title: "CUNY MSDA 607 Spring 2016 Project 4"
author: "James Topor"
date: "April 3, 2016"
output: 
    html_document:
        toc: true
        depth: 3
        number_sections: FALSE
        theme: spacelab
        highlight: tango
---

__---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------__

# Introduction

For this project we are asked to take information from a relational database and migrate it to a NoSQL database of our own choosing. For the relational database we'll make use of the 'tb' database we constructed within __MySQL__ for Assignment #3. For the NoSQL database we'll make use of __MongoDB__.

The basic approach will be to first retrieve the tuberculosis data from the 'tb' MySQL database and load it into an R data frame. The contents of that data frame will then be loaded into MongoDB, with the results of the loading process being verified through the use of both simple MongoDB commands and MongoDB queries. If the process functions properly we should be able to fetch data from MongoDB that matches what we have in our R data frame.

*__IMPORTANT: The approach used here assumes the user has both __MySQL__ and __MongoDB__ installed and operating properly within their own local computing environment. Please note that the user may need to adjust the database connectivity arguments used herein to match the settings of their own local __MySQL__ and __MongoDB__ configurations. Failure to do so may result in this R code not being able to function properly.__*

__---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------__

# Loading the Tuberculosis ('tb') Data From MySQL

We'll make use of R's __RODBC__ package to connect with the 'tb' database housed on our local __MySQL__ server.

*__IMPORTANT: This R code assumes that the user has the required 'tb' database installed within their own local __MySQL__ server. If the user does not have the 'tb' database installed, please download the 'tbdbcreate.sql' and 'tb.csv' files accessible via the following github links and install the database, bearing in mind that you may need to alter the 'LOAD DATA INFILE' command given on Line 27 of that file so that it comports with your specific computing environment. The 'tb.csv' file contains the data that will populate the 'tb' database. The data are automatically loaded into the database via the SQL sript's 'LOAD DATA INFILE' command mentioned above.__*

Path to 'tbdbcreate.sql' SQL script file:  
https://raw.githubusercontent.com/jtopor/CUNY-MSDA-607/master/tbdbcreate.sql  

Path to 'tb.csv' data file:  
https://raw.githubusercontent.com/jtopor/CUNY-MSDA-607/master/tb.csv


```{r, warning=FALSE, message=FALSE}
# load the RODBC library for access to MySQL server
library(RODBC)
library(knitr)

# establish connection to local MySQL server
# NOTE: Be sure to set the server reference appropriately to conform with your own local 
# computing environment. On my machine the server is referenced by "local_server", but the
# reference term on your machine might be different
con <- odbcConnect("local_server")

# select a database to use - in this case, the 'ds_skills' database
sqlQuery(con, "use tb")
```

The __tb__ database contains a single table, also named 'tb', comprised of six columns and defined within the SQL database as follows:

1) country  varchar(100) NOT NULL   
2) year int NOT NULL,  
3) sex varchar(6) NOT NULL,  
4) child int NULL,  
5) adult int NULL,  
6) elderly int NULL  

Each record within the __tb__ database tells us how many individuals of a given age category ('child', 'adult', or 'elderly') of a given gender were diagnosed with tuberculosis within a given country for a given year.

The tuberculosis data can be sorted and loaded into an R dataframe with the following SQL query:
```{r}
tb_df <- sqlQuery(con, "SELECT country, year, SUM(child + adult + elderly) FROM tb
						GROUP BY country, year ORDER BY country, year", stringsAsFactors=F)

# rename third column to meaningful name
colnames(tb_df)[3] <- "cases"
nrow(tb_df)
kable(head(tb_df))
```

As shown above, our SQL query has loaded 1900 rows of data from the 'tb' table housed within the 'tb' database. We've used the query to sort the data alphabetically by country name and order the records for any given country in chronological order by year. Furthermore, we've summed the various valid *'age/gender'* category counts so that rather than having 3 separate rows of data for each given country/year pairing we have a single consolidated row of data that shows the total number of tuberculosis cases recorded for any given country/year pairing.

We have one minor data cleansing task to attend to before we attempt to load the tuberculosis data into MongoDB: as was discovered in Assignment 3, one of the country name identifiers used for the country of Ivory coast ("Côte d'Ivoire") contains special characters. Those special characters will not load cleanly into MongoDB for some unknown reason. As such, we will simply change the country name "Côte d'Ivoire" within our data frame to "Ivory Coast":

```{r}
# rename Côte d'Ivoire sp that special chars removed
tb_df$country[tb_df$country == "Côte d'Ivoire"] <- 'Ivory Coast'
```

Since we've completed our intended usage of the MySQL relational database, we'll now close the connection we made to the MySQL server:
```{r}
# close the database connection
odbcClose(con)
```

__---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------__

# Using the MySQL Data Frame to Populate a MongoDB Collection

For purposes of this project a 64-bit Windows-based version of MongoDB was installed. The MongoDB software was configured as a Windows Service so that it is made available whenever the machine is booted. Please note that installation and configuration procedures for MongoDB are beyond the scope of this project. Please refer to the MongoDB website (__www.mongodb.com__) if you require instructions for those procedures.

To access the MongoDB system we'll make use of the __rmongodb__ package. Since MongoDB is a NoSQL database platform, we need to adhere to the MongoDB construct of storing data in "Collections" that reside within a "Database". A "Collection" can be comprised of many types of data, and as such is considered to be unstructured in the sense that the items within it do not need to conform to a standard format or data structure.

A database named "test" has previously been created within our MongoDB environment during the installation process. For this project we'll construct a new collection within the "test" database called "test.tb" to house the tuberculosis data we've loaded into our R data frame from the MySQL database. 

We'll start by loading the __rmongodb__ package, creating a connection to the MongoDB server, checking to ensure we have a valid connection to the MongoDB system, and setting a variable to the name of our new collection, "test.tb".

```{r, warning=FALSE, message=FALSE}
library(rmongodb)

# create a connection to the Mongo service
mongo <- mongo.create()

# check to ensure connection was established
mongo.is.connected(mongo)

# set the collection name to be used
coll <- "test.tb"
```

We now check the row count of the "test.tb" collection to verify that it is, in fact, devoid of content prior to our attempts to add to it:
```{r}
# check row count before inserts
mongo.count(mongo, coll)
```

Inserting the contents of the R data frame into MongoDB requires that we follow the following steps:

1. Convert each row within the data frame to a list using R's __as.list__ function;

2. Convert the list from Step 1 to the BSON format using __rmongodb__'s __mongo.bson.from.list__ function;

3. Use the __mongo.insert__ function to add the BSON formatted item to MongoDB

We'll do this via a __for__ loop and then check the count of the number of items that have been added to the MongoDB "test.tb" collection to verify that it matches the 1900 row size of our tb_df data frame:

```{r}
# Inserting data into Mongo DB

# Loop through tb_df and insert each item into MongoDB
if(mongo.is.connected(mongo) == TRUE){
  for( i in 1: nrow(tb_df) ) {
    # convert dataframe row to list
    tb_aslist <- as.list(tb_df[i,])
    
    # convert list to BSON format
    test_q <- mongo.bson.from.list(tb_aslist)
    
    # insert BSON formatted df item into MongoDB
    mongo.insert(mongo, coll, test_q )
  } # end for
  
} # end if

# Using the command mongo.count, we can check how many documents are in the collection or in the result of a specific query. More information for all functions can be found in the help files.
mongo.count(mongo, coll)
```

As shown above, R's __mongo.count__ function informs us that we now have 1900 rows housed within the "test.tb" collection. This tells us that we have at a minumum added the same number of items to MongoDB as we had in our tb_df dataframe.

__---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------__

# Verifying the MongoDB Data We've Loaded

Now that we've loaded data into MongoDB we can run some queries against the "test.tb" collection to see if what we've loaded accurately reflects the contents of the data frame we built from the MySQL database data. We'll start with a query that returns the distinct country names housed within the "test.tb" collection:
```{r}
qres <- mongo.distinct(mongo, coll, "country")
length(qres)
head(qres)
```

Our results tell us that we have 100 unique country names housed within the "test.tb" collection, and we've printed out the first handful of country names via R's __head__function.

Let's see if we get the same results if we query the tb_df data frame we generated from the contents of the MySQL 'tb' database:

```{r}
qres2 <- unique(tb_df$country)
length(qres2)
head(qres2)
```

The results match. Let's try another query where we ask MongoDB to return all of the items from the "test.tb" collection having "Turkey" as the 'country':

```{r}

# fetch all records where country = Turkey

# build query string
query <- mongo.bson.from.list(list('country' = 'Turkey'))
query

# submit query and get count of results/rows
qres <- mongo.find.all(mongo, coll, query)
length(qres)
```

As we can see, the query has returned 19 records from MongoDB. Unfortunately, the structure of the object returned by the __mongo.find.all__ function is a list of lists and as such does not lend itself to easy viewing within the R environment. Therefore, we'll have to transform the contents of the __qres__ variable if we wish to view the results of the query in a coherent manner. To that end we make use of an algorithm suggested at the following web page:

https://gist.github.com/Btibert3/7751989

The algorithm suggested therein has been modified to account for the fact that the object returned by the __mongo.find.all__ function is not, in fact, of the class "mongo.cursor", but is in fact a list of lists. A __for__ loop is implemented in place of the __while__ loop suggested by the author and various other changes have also been made to allow the algorithm to conform to the needs of this project.

```{r}
library(plyr)
m_res.df <- data.frame(stringsAsFactors = FALSE)

## iterate through the list of lists and create a clean, displayable data frame
for( i in 1: length(qres) ) {
    # iterate and grab the next record
    tmp = qres[[i]]
    # make it a dataframe
    tmp.df = as.data.frame(t(unlist(tmp)), stringsAsFactors = F)
    # bind to the master dataframe
    m_res.df = rbind.fill(m_res.df, tmp.df)
}

# strip the ID column from the data frame - not needed for display
qres.df <- data.frame(m_res.df$country, m_res.df$year, m_res.df$cases)

# display
kable(qres.df)
```



Let's query the tb_df data frame to see if our results match those we obtained from MongoDB:

```{r}
kable(subset(tb_df, country == "Turkey"), row.names = FALSE)
```

As we can see, the results do match. Now let's try a more specific query: let's fetch the tuberculosis record for the country of Kenya for the year 2002:

```{r}
query <- mongo.bson.from.list(list('country' = 'Kenya', 'year' = 2002))

# submit query
qres2 <- mongo.find.all(mongo, coll, query)

# make it a dataframe
tmp.df = as.data.frame(t(unlist(qres2[[1]])), stringsAsFactors = F)

# strip ID column from data frame - not needed for display
qres2.df <- data.frame(tmp.df$country, tmp.df$year, tmp.df$cases)

# display
kable(qres2.df)
```

The results look realistic. Let's check our data frame to see if they match:

```{r}
kable(subset(tb_df, country == "Kenya" & year == 2002), row.names = FALSE)
```

As we can see, the results do, in fact, match. Based on these sample queries it appears as though we've successfully taken data from a MySQL database and loaded it into MongoDB.

Now that we've completed the assignment we can purge the "test.tb" collection we've created from the MongoDB server and close the R connection to MongoDB:

```{r]}
# purge collection for testing purposes
purged <- mongo.drop(mongo, coll)
purged

# close connection
mongo.destroy(mongo)
```

__---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------__

# Relational Databases vs. NoSQL Databases


Briefly describe the advantages and disadvantages of storing the data in a relational database vs. your NoSQL database.

This project provided an opportunity to make use of two very different types of database platforms: a relational database (__MySQL__) and a NoSQL database (__MongoDB__). Each of these platforms has their own advantages and disadvantages for purposes of storing and managing collections of data. We now discuss these factors as they relate to relational databases in general and MongoDB specifically as a NoSQL database system.

## Relational Databases: Advantages & Disadvantages

Relational databases have been widely used for more than 25 years now. They share a common query language (SQL), a common methodology for storing, retrieving, and managing data, and a common set of methods for adding, modifying, and deleting their contents. Relational databases excel at the task of storing and managing __structured data__ that requires high levels of data integrity (e.g., consistent data indexing; non-duplicative data content; etc.) and a clear, concise method for retrieving that data in a structured manner. Successful applications of relational database technology are too numerous to list, but include many aspects of common business processes such as accounting, finance, human resources management, and many more.

The disadvantages of relational databases can be found in the relative challenge many users encounter when attempting to store and manage unstructured data, including large binary objects such as digital images, video, audio clips, and collections of documents that may share a common subject matter but not a common format. The unstructured nature of such files and data can make it difficult to define a coherent relational database storage model that will enable efficient storage and retrieval of such data.

## NoSQL Databases: Advantages & Disadvantages

Unlike relational databases, NoSQL databases have not been widely used for an extended period of time, do not share a common query language, do not share a common methodology for storing, retrieving, and managing data, and do not share a common set of methods for adding, modifying and deleting their contents. However, NoSQL databases excel at the task of storing and managing __unstructured data__ such as digital images, videos, audio clips, and collections of documents that may share a common subject matter but not a common format. Basically, a NoSQL database is a storage space into which a user can deposit virtually any type of digital object. The database provides a simple user-defined index to each object, and virtually no internal data integrity/consistency checks are performed on the database's contents as items are added, modified or deleted. Such an environment can be very useful for purposes such as software application development, storage of web-based audio/video, and for storing collections of documents that share no common format.

The disadvantages of NoSQL databases are basically their failure to provide any of the advantages of a relational database. In particular, the lack of a common query language and lack of built-in data integrity tools makes them unsuitable for many types of applications. For example, lack of a common query language serves as a major impediment to migrating a NoSQL-based application from, say, MongoDB to a different NoSQL platform such as Hadoop.

Furthermore, the fact that NoSQL databases seem to have proprietary methods for adding, modifying, deleting, and querying their contents serves as a major impediment for application developers. For example, MongoDB requires that all queries and any data being added to its platform be converted to BSON format, which itself is not widely used outside of the MongoDB environment. Within R, converting to BSON format requires that numeric or character data first be converted to JSON format, and then converted to BSON. Requiring users to perform multiple data format conversions prior to adding them to a database is woefully inefficient and wasteful. Similarly, when retrieving data back from MongoDB within R, the user receives that data in BSON format, which of course subsequently must be converted to an R data structure that is suitable for manipulation within R.

## The Bottom Line: Relational vs. NoSQL

In summary, both relational databases and NoSQL each have their own strengths and weaknesses, many of which appear to be diametrically opposed to those of the other. As such, an application developer should think carefully about their data integrity and storage needs as well as whether they require platform-independent code before choosing either one. 